import tritonclient.http as httpclient
import numpy as np
import os
import base64
import cv2
from openai import OpenAI
from dotenv import load_dotenv
import pandas as pd
import re
import shutil

# === Triton ì„¤ì • ===
TRITON_URL = "202.79.101.81:55124"
MODEL_NAME = "ensemble"

# === Triton í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì „ì—­ìœ¼ë¡œ í•œ ë²ˆë§Œ)
triton_client = httpclient.InferenceServerClient(url=TRITON_URL)

# === OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± (í™˜ê²½ë³€ìˆ˜ì—ì„œ í‚¤ ë¶ˆëŸ¬ì˜´)
load_dotenv()
openai_client = OpenAI()

# === ìœ í‹¸: ì´ë¯¸ì§€ base64 ì¸ì½”ë”© ===
def encode_image_base64(image_path):
    with open(image_path, "rb") as f:
        encoded = base64.b64encode(f.read()).decode("utf-8")
        if len(encoded) % 4:
            encoded += "=" * (4 - len(encoded) % 4)
        return encoded

# === ìœ í‹¸: ë°”ì´íŠ¸í˜• ìˆ«ì ë””ì½”ë”© ===
def decode_float(x):
    try:
        return float(x.decode("utf-8")) if isinstance(x, bytes) else float(x)
    except:
        return 0.0

# === í…ìŠ¤íŠ¸ bbox ì‹œê°í™” í•¨ìˆ˜ ===
def draw_bboxes_on_image(image_path, texts, output_path):
    image = cv2.imread(image_path)
    for t in texts:
        x1, y1, x2, y2, text, _ = t
        x1, y1, x2, y2 = map(decode_float, [x1, y1, x2, y2])
        pt1 = (int(x1), int(y1))
        pt2 = (int(x2), int(y2))
        label = text.decode("utf-8") if isinstance(text, bytes) else str(text)

        cv2.rectangle(image, pt1, pt2, (0, 255, 0), 2)
    
    cv2.imwrite(output_path, image)

# === í•µì‹¬ í•¨ìˆ˜ ===
def run_ocr_gpt_pipeline(image_path: str, key_list: list = None) -> tuple[pd.DataFrame, str]:
    # === 1. Triton ì¶”ë¡  ===
    encoded_image = encode_image_base64(image_path)
    inputs = httpclient.InferInput("input_image", [1], "BYTES")
    inputs.set_data_from_numpy(np.array([encoded_image], dtype=object))

    outputs = [
        httpclient.InferRequestedOutput("final_texts_with_line"),
        httpclient.InferRequestedOutput("html_tags")
    ]

    response = triton_client.infer(model_name=MODEL_NAME, inputs=[inputs], outputs=outputs)
    texts = response.as_numpy("final_texts_with_line")
    html = response.as_numpy("html_tags")

    # === 2. OCR í…ìŠ¤íŠ¸ êµ¬ì„± ===
    ocr_lines = []
    for t in texts:
        x1, y1, x2, y2, text, line_num = t
        x1, y1, x2, y2 = map(decode_float, [x1, y1, x2, y2])
        text = text.decode("utf-8") if isinstance(text, bytes) else str(text)
        ocr_lines.append(f"[{x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f}] \"{text}\"")

    ocr_text_block = "\n".join(ocr_lines)
    html_text = "\n".join(line.decode("utf-8") for line in html)

    # === 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„± ===
    key_prompt = ""
    clean_keys = [k.strip() for k in key_list if k.strip()] if key_list else []
    if clean_keys:
        key_prompt = (
            "\n\nğŸ“Œ ì•„ë˜ í•­ëª©ë“¤ì€ ë°˜ë“œì‹œ ê²°ê³¼ì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ëˆ„ë½ë˜ì—ˆë‹¤ë©´ ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë¼ë„ í¬í•¨ì‹œì¼œì£¼ì„¸ìš”:\n"
            + "\n".join(f"- {key}: ë¯¸ê²€ì¶œ" for key in clean_keys)
        )

    prompt = f"""
    ë‹¤ìŒì€ ì‹ ì²­ì„œ ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ í‘œì™€ OCR í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

    ì´ ë¬¸ì„œì—ì„œ ì˜ë¯¸ ìˆëŠ” key-value ì •ë³´ë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”.
    ê° í•­ëª©ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

    key: value

    í‘œì˜ êµ¬ì¡°ì™€ OCR í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ìì²´ë¥¼ ëª¨ë‘ ê³ ë ¤í•´ì„œ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë½‘ì•„ì£¼ì„¸ìš”.
    ì´ë¯¸ì§€ì˜ ì†ê¸€ì”¨ ì •ë³´ë¥¼ ê³ ë ¤í•´ì„œ valueê°’ì„ ì •í•´ì£¼ì„¸ìš”.
    ê°™ì€ keyê°’ì´ ìˆì„ ë•Œ, í‘œì˜ êµ¬ì¡°ì™€ ë¬¸ì„œë¥¼ ì˜ ë¶„ì„í•´ì„œ ë‹¤ë¥´ê²Œ êµ¬ë¶„í•´ì£¼ì„¸ìš”.
    ì²´í¬ë¦¬ìŠ¤íŠ¸ë„ ìœ ì˜í•´ì„œ ê³µë€ì¸ì§€ ì²´í¬ë˜ì–´ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.
    ê´„í˜¸ ê³µë€, ì„œëª…ë€ ë“±ì´ ìˆëŠ” ê²½ìš°ëŠ”, ê·¸ ë¶€ë¶„ë“¤ë§Œ ëº€ ë‹¨ì–´ë“¤ë¡œ ê³ ë ¤í•´ì£¼ì„¸ìš”.{key_prompt}

    ğŸ“Œ í‘œ (HTML):
    {html_text}

    ğŸ“Œ OCR í…ìŠ¤íŠ¸ ë°•ìŠ¤:
    {ocr_text_block}
    """

    # === 4. GPT í˜¸ì¶œ ===
    response = openai_client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
        seed=1
    )

    gpt_output = response.choices[0].message.content
    gpt_output = re.sub(r"\*\*", "", gpt_output)

    # === 5. key-value íŒŒì‹±
    def extract_key_value_pairs(text):
        lines = text.strip().split('\n')
        pairs = []
        for line in lines:
            if ":" in line:
                key, value = line.split(":", 1)
                key = key.strip()
                value = value.strip()
                if key:
                    pairs.append((key, value))
        return pairs

    kv_pairs = extract_key_value_pairs(gpt_output)

    # === 6. ëˆ„ë½ëœ key ë³´ì™„
    if clean_keys:
        existing_keys = {k for k, _ in kv_pairs}
        for k in clean_keys:
            if k not in existing_keys:
                kv_pairs.append((k, "ë¯¸ê²€ì¶œ"))

    df = pd.DataFrame(kv_pairs, columns=["Key", "Value"])

    # === 7. bbox ì´ë¯¸ì§€ ì €ì¥
    output_image_path = image_path.replace(".jpg", "_bbox.jpg").replace(".png", "_bbox.jpg")
    draw_bboxes_on_image(image_path, texts, output_image_path)

    # === 8. static í´ë”ë¡œ ë³µì‚¬ (í”„ë¡ íŠ¸ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ)
    result_image_path = os.path.join("static/results", os.path.basename(output_image_path))
    os.makedirs(os.path.dirname(result_image_path), exist_ok=True)
    shutil.copy(output_image_path, result_image_path)

    return df, result_image_path
