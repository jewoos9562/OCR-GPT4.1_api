import tritonclient.http as httpclient
import numpy as np
import os
import base64
from PIL import Image
from openai import OpenAI
from dotenv import load_dotenv

# === Triton ì„¤ì • ===
TRITON_URL = "localhost:8000"
MODEL_NAME = "ensemble"
input_image_path = "/workspace/sample_images/IMG_OCR_6_F_0005207.png"
save_folder = "/workspace/result"
os.makedirs(save_folder, exist_ok=True)

# === Triton client ìƒì„± ===
client_triton = httpclient.InferenceServerClient(url=TRITON_URL)

# === ì´ë¯¸ì§€ base64 ì¸ì½”ë”© ===
def encode_image_base64(image_path):
    with open(image_path, "rb") as f:
        encoded = base64.b64encode(f.read()).decode("utf-8")
        if len(encoded) % 4:
            encoded += "=" * (4 - len(encoded) % 4)
        return encoded

# === Triton ì…ë ¥ ë°ì´í„° êµ¬ì„± ===
encoded_image = encode_image_base64(input_image_path)
inputs = httpclient.InferInput("input_image", [1], "BYTES")
inputs.set_data_from_numpy(np.array([encoded_image], dtype=object))

outputs = [
    httpclient.InferRequestedOutput("final_texts_with_line")
]

# === Triton ì¶”ë¡  ===
response = client_triton.infer(model_name=MODEL_NAME, inputs=[inputs], outputs=outputs)
texts = response.as_numpy("final_texts_with_line")  # (N, 6)

# === ìœ„ì¹˜ ì •ë³´ + í…ìŠ¤íŠ¸ ì •ë¦¬ ===
def decode_float(x):
    if isinstance(x, bytes):
        return float(x.decode("utf-8"))
    return float(x)

structured_lines = []
for t in texts:
    x1, y1, x2, y2, text, line_num = t
    x1, y1, x2, y2 = map(decode_float, [x1, y1, x2, y2])
    text = text.decode("utf-8") if isinstance(text, bytes) else str(text)
    structured_lines.append(f"[{x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f}] \"{text}\"")

ocr_summary = "\n".join(structured_lines)

# === LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„± ===
prompt = f"""
ë‹¤ìŒì€ ë¬¸ì„œ ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ OCR í…ìŠ¤íŠ¸ì™€ ìœ„ì¹˜ ì •ë³´ì…ë‹ˆë‹¤.
ê° í…ìŠ¤íŠ¸ëŠ” í•´ë‹¹ ë¬¸ì„œì˜ ìœ„ì¹˜ ì¢Œí‘œì™€ í•¨ê»˜ ì£¼ì–´ì§‘ë‹ˆë‹¤.
ì´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì„œì— í¬í•¨ëœ ì¤‘ìš”í•œ key-value ìŒì„ ì¶”ì¶œí•´ì¤˜.
í¼ì˜ êµ¬ì¡°ë¥¼ ì´í•´í•˜ê³  ê°€ëŠ¥í•œ ì •ë¦¬ëœ ë°©ì‹ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.

OCR ê²°ê³¼:
{ocr_summary}
"""

# === OpenAI API í˜¸ì¶œ ===
load_dotenv()  # .envì—ì„œ OPENAI_API_KEY ë¡œë”©
client = OpenAI()

response = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.2,
    max_tokens=1500
)

# === ê²°ê³¼ ì¶œë ¥ ===
print("ğŸ“„ ì¶”ì¶œëœ Key-Value ìš”ì•½:")
print(response.choices[0].message.content)
