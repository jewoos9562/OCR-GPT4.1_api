import tritonclient.http as httpclient
import numpy as np
import os
import base64
from PIL import Image
from openai import OpenAI
from dotenv import load_dotenv

# === Triton ì„¤ì • ===
TRITON_URL = "localhost:8000"
MODEL_NAME = "ensemble"
input_image_path = "/workspace/sample_images/IMG_OCR_6_F_0005207.png"
save_folder = "/workspace/result"
os.makedirs(save_folder, exist_ok=True)

# === Triton í´ë¼ì´ì–¸íŠ¸ ìƒì„± ===
client = httpclient.InferenceServerClient(url=TRITON_URL)

# === ì´ë¯¸ì§€ base64 ì¸ì½”ë”© ===
def encode_image_base64(image_path):
    with open(image_path, "rb") as f:
        encoded = base64.b64encode(f.read()).decode("utf-8")
        if len(encoded) % 4:
            encoded += "=" * (4 - len(encoded) % 4)
        return encoded
    

# === Triton ì…ë ¥ ===
encoded_image = encode_image_base64(input_image_path)
inputs = httpclient.InferInput("input_image", [1], "BYTES")
inputs.set_data_from_numpy(np.array([encoded_image], dtype=object))

outputs = [
    httpclient.InferRequestedOutput("final_texts_with_line"),
    httpclient.InferRequestedOutput("html_tags")
]

response = client.infer(model_name=MODEL_NAME, inputs=[inputs], outputs=outputs)

# === ê²°ê³¼ ì¶”ì¶œ ===
texts = response.as_numpy("final_texts_with_line")  # (N, 6)
html = response.as_numpy("html_tags")               # (T,)

# === HTML í…ìŠ¤íŠ¸ êµ¬ì„± ===
html_text = "\n".join(line.decode("utf-8") for line in html)

# === OCR í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ êµ¬ì„± ===
def decode_float(x):
    if isinstance(x, bytes):
        return float(x.decode("utf-8"))
    return float(x)

ocr_lines = []
for t in texts:
    x1, y1, x2, y2, text, line_num = t
    x1, y1, x2, y2 = map(decode_float, [x1, y1, x2, y2])
    text = text.decode("utf-8") if isinstance(text, bytes) else str(text)
    ocr_lines.append(f"[{x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f}] \"{text}\"")

ocr_text_block = "\n".join(ocr_lines)

# === OpenAI ì„¤ì • ===
load_dotenv()  # .envì— OPENAI_API_KEY ì €ì¥ë˜ì–´ ìˆì–´ì•¼ í•¨
openai_client = OpenAI()

# === í”„ë¡¬í”„íŠ¸ êµ¬ì„± ===
prompt = f"""
ë‹¤ìŒì€ í•œ ì‹ ì²­ì„œ ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ HTML í…Œì´ë¸”ê³¼ OCR í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

ì´ ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ keyê°’ê³¼ valueë¥¼ ì •ë¦¬í•´ì¤˜.
í‘œì˜ êµ¬ì¡°ë¥¼ ì˜ ì´í•´í•´ì„œ ì •ë¦¬í•´ì¤˜
ì—‘ì…€ íŒŒì¼ì— ì €ì¥í• ê±°ë‹ˆê¹Œ êµ¬ì¡°í™”ë¥¼ ì˜í•´ì£¼ë©´ ì¢‹ê² ì–´

ğŸ“Œ í‘œ (HTML):
{html_text}

ğŸ“Œ OCR í…ìŠ¤íŠ¸ ë°•ìŠ¤:
{ocr_text_block}
"""

# === GPT ìš”ì²­ ===
response = openai_client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.3
)

# === ê²°ê³¼ ì¶œë ¥ ===
print("ğŸ§¾ ìš”ì•½ ê²°ê³¼:")
print(response.choices[0].message.content)
